#!/usr/bin/env python3

import argparse
import os
import datetime
import subprocess

DB = os.path.join(os.path.dirname(__file__), 'db/')

def get_version():
	print("BEGIN")
	print(os.path.join(os.path.dirname(__file__),""))
	try:
		# if os.path.dirname(__file__) == True:
			# version = subprocess.check_output(["git", "describe"], cwd= os.path.join(os.path.dirname(__file__),"")).strip().decode("utf-8")
		# else:
		version = subprocess.check_output(["git", "describe"]).strip().decode("utf-8")
	except subprocess.CalledProcessError:
		version = "version not available (did you 'git clone'?)"
	print("END")
	return(version)

def create_config(config_file, args):
	if os.path.exists(config_file):
		print("\nWARNING: The file "+config_file+" already exists. It will be replaced.\n")
		os.remove(config_file)
	else:
		print("\nCreating config file.\n")
		
	# chimera method:
	if args.chim_denovo and args.chim_ref:
		chim_method = "denovo_reference"
	elif args.chim_denovo:
		chim_method = "denovo"
	elif args.chim_ref:	
		chim_method = "reference"
	else:
		chim_method = "None"
		
	with open(config_file, 'w') as conf:
		conf.write("""# This config file was automatically generated by foodme.py 
# Version : {ver}
# Date: {date}

workdir: "{workdir}"
samples: "{sample_list}"
threads_sample: {threads_sample} 
threads: {threads}

workflow:
    clustering: {clustering}
    taxonomy: {taxonomy}

fastp:
    length_required: {fastp_length}
    qualified_quality_phred: {fastp_min_phred}
    window_size: {fastp_window}
    mean_quality: {fastp_meanq} 

read_filter:
    min_length: {merge_minlength}
    max_length: {merge_maxlength}
    max_expected_errors: {merge_maxee}

chimera:
    method: {chimera_method}
    chimera_DB: {chimera_db}
    
cluster:
    cluster_identity: {cluster_id}
    cluster_minsize: {cluster_minsize}
    
sintax:
    sintax_db: {sintax_db}
    sintax_cutoff: {sintax_cutoff}

blast:
    blast_DB: {blastdb}
    taxdb: {taxdb}
    e_value: {e_val}
    perc_identity: {blast_id}
    qcov: {blast_qcov}
    bit_score_diff: {bitscore}
    names_dmp: {names_dmp}
    nodes_dmp: {nodes_dmp}

""".format(date=datetime.datetime.now(),
		ver=get_version(),
		workdir=args.working_directory,
		sample_list=args.sample_list,
		threads_sample=args.threads_sample,
		threads=args.threads,
		clustering=args.clustering,
		taxonomy=args.taxonomy,
		fastp_length=args.fastp_length,
		fastp_min_phred=args.fastp_min_phred,
		fastp_window=args.fastp_window,
		fastp_meanq=args.fastp_meanq,
		merge_minlength=args.merge_minlength,
		merge_maxlength=args.merge_maxlength,
		merge_maxee=args.merge_maxee,
		cluster_id=args.cluster_id,
		chimera_method= chim_method,
		chimera_db=args.chim_ref,
		blastdb=args.blastdb,
		taxdb=args.taxdb,
		e_val=args.e_val,
		blast_id=args.blast_id,
		blast_qcov=args.blast_cov,
		bitscore=args.bitscore,
		names_dmp=args.names_dmp,
		nodes_dmp=args.nodes_dmp,
		cluster_minsize=args.cluster_minsize,
		sintax_db=args.sintaxdb,
		sintax_cutoff=args.sintax_cutoff))
	
def run_snakemake(config_file, args):
	forceall = ("--forceall" if args.forceall else "")
	dryrun = ("-n" if args.dryrun else "")
	conda_prefix= ("--conda-prefix {}".format(args.condaprefix) if args.condaprefix else "")
	notemp = ("" if args.clean_temp else "--notemp")
	call = "snakemake -s {snakefile} --configfile {config_file} --use-conda --cores {cores} {conda_prefix} {notemp} {forceall} {dryrun}".format(snakefile= args.snakefile,
																																	config_file= config_file,
																																	conda_prefix= conda_prefix,
																																	forceall= forceall,
																																	dryrun = dryrun,
																																	cores=args.threads,
																																	notemp=notemp)
	print(call)
	subprocess.call(call, shell=True)
	
def main(): 
	parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter, prog = "FooDMe", description= "Another Pipeline for (Food) DNA metabarcoding")
	parser.add_argument('-v', '--version', action='version', version="FooDMe version: "+ get_version(), help="Print Pipeline version and exit")
	
	# Path arguments
	ioargs = parser.add_argument_group('I/O path arguments')
	ioargs.add_argument('-l', '--sample_list', required=True, type=os.path.abspath, 
						help="Tab-delimited list of samples and paths to read files. Must contain one line of header, each further line contains sample_name, read1_path, read2_path")
	ioargs.add_argument('-d', '--working_directory', required=True, type=os.path.abspath,
						help="Directory to create output files")
						
	# Snakemake arguments
	smkargs = parser.add_argument_group('Snakemake arguments')
	smkargs.add_argument('--forceall', required=False, default=False, action='store_true',
						help="Force the recalculation of all files")
	smkargs.add_argument('-n', '--dryrun', required=False, default=False, action='store_true',
						help="Dryrun. Create config file and calculate the DAG but do not execute anything")
	smkargs.add_argument('-t', '--threads', required=False, default=8, type=int,
						help="Maximum number of threads to use")
	smkargs.add_argument('--threads_sample', required=False, default=1, type=int,
						help="Number of threads to use per concurent job")
	smkargs.add_argument('-c', '--condaprefix', required=False, type=os.path.abspath, default=False,
						help="Location of stored conda environment. Allows snakemake to reuse environments.")
	smkargs.add_argument('-s', '--snakefile', required=False, type=os.path.abspath, default=os.path.join(os.path.dirname(__file__), "Snakefile"), 
						help="Path to the Snkefile in the FOodMe repo")
	smkargs.add_argument('--clean_temp', required=False, default= False, action='store_true',
						help="Remove large fasta and fastq files to save storage space")
						
	# Workflow
	flow = parser.add_argument_group('Method choices')
	flow.add_argument('--clustering', required = False, choices = ['vsearch'], type = str, default= 'vsearch',
						help='Clustering method. Only VSearch possible')
	flow.add_argument('--taxonomy', required=False, choices = ['blast', 'sintax'], type = str, default= 'blast',
						help='Taxonomic assignment method')
						
	# Fastp
	fastpargs = parser.add_argument_group('Fastp options')
	fastpargs.add_argument('--fastp_length', required=False, default=50, type=int,
						help="Minimum length of input reads to keep")
	fastpargs.add_argument('--fastp_min_phred', required=False, default=15, type=int,
						help="Minimal quality value per base")
	fastpargs.add_argument('--fastp_window', required=False, default=4, type=int,
						help="Size of the sliding window for tail quality trimming")
	fastpargs.add_argument('--fastp_meanq', required=False, default=20, type=int,
						help="Minimum mean Phred-score in the sliding window for tail quality trimming")					
						
	# Read filter
	readargs = parser.add_argument_group('Merged reads filtering options')
	readargs.add_argument('--merge_minlength', required=False, default=200, type=int,
						help="Minimum length merged reads to keep")
	readargs.add_argument('--merge_maxlength', required=False, default=600, type=int,
						help="Maximum length merged reads to keep")
	readargs.add_argument('--merge_maxee', required=False, default=1, type=int,
						help="Maximum expected errors in merged reads to keep")
	
	# Cluster
	clsargs = parser.add_argument_group('Clustering options')
	clsargs.add_argument('--cluster_id', required=False, default=0.97, type=float,
						help="Minimum identity for clustering sequences in OTUs (between 0 and 1)")
	clsargs.add_argument('--cluster_minsize', required=False, default=2, type=int,
						help="Minimal size cutoff for clusters")
	
	# Chimera
	chimargs = parser.add_argument_group('Chimera detection options')
	chimargs.add_argument('--chim_denovo', required=False, default=False, action='store_true',
						help="Perform de novo chimera detection and filtering")
	chimargs.add_argument('--chim_ref', required=False, type=os.path.abspath, default=False,
						help="Path to the database for chimera detection. If omitted, reference-based chimera filtering will be skipped.")

	# Sintax
	sintax = parser.add_argument_group('Options for SINTAX search and taxonomy consensus determination')
	sintax.add_argument('--sintaxdb', required = False, type= os.path.abspath,
						default=os.path.join(DB, "sintax/mitochondrion.LSU.sintax.faa"),
						help="Path to the SINTAX database (FASTA)")
	sintax.add_argument('--sintax_cutoff', required=False, type= float, default= 0.9,
						help="Bootstrap cutoff value for taxonomic support")
	
	# Blast
	blastargs = parser.add_argument_group('Options for BLAST search and taxonomy consensus determination')
	blastargs.add_argument('--blastdb', required=False, type=os.path.abspath,
						default=os.path.join(DB, "blast/mitochondrion.LSU.faa"),
						help="Path to the BLAST database (FASTA)")
	blastargs.add_argument('--taxdb', required=False, type=os.path.abspath,
						default=os.path.join(DB, "blast/"),
						help="Path to the BLAST taxonomy database (folder)")
	blastargs.add_argument('--e_val', required=False, default=1e-30, type=float,
						help="E-value threshold for blast results")
	blastargs.add_argument('--blast_id', required=False, default=97, type=float,
						help="Minimal identity between the hit and query for blast results (in percent)")
	blastargs.add_argument('--blast_cov', required=False, default=97, type=float,
						help="Minimal proportion of the query covered by a hit for blast results. A mismatch is still counting as covering (in percent)")
	blastargs.add_argument('--bitscore', required=False, default=128, type=int,
						help="Maximum bit-score difference with the best hit for a blast result to be included in the taxonomy consensus detemination")
	blastargs.add_argument('--nodes_dmp', required=False, type=os.path.abspath,
						default=os.path.join(DB, "taxdump/nodes.dmp"),
						help="Path to the nodes.dmp file")
	blastargs.add_argument('--names_dmp', required=False, type=os.path.abspath,
						default=os.path.join(DB, "taxdump/names.dmp"),
						help="Path to the names.dmp file")	
	
	args = parser.parse_args()
	
	# Check constraints
	if args.cluster_id > 1 or args.cluster_id < 0:
		parser.error("'--cluster_id' value must be between 0 and 1")
	if args.blast_id > 100 or args.blast_id < 0:
		parser.error("'--blast_id' value must be between 0 and 100")
	if args.blast_cov > 100 or args.blast_cov < 0:
		parser.error("'--blast_cov' value must be between 0 and 100")
	if args.sintax_cutoff > 1 or args.sintax_cutoff < 0:
		parser.error("'--sintax_cutoff' value must be between 0 and 1")
		
	# check files
	for path in [args.blastdb, args.taxdb]:
		if not os.path.exists(path):
			print("\nIt seems a database is missing. See Error below.\nYou can create the blast database by using the 'create_blast_db.sh' script.\n")
			raise OSError(2, "No such file or directory" , path)
	
	# Create workdir
	if not os.path.exists(args.working_directory):
		os.makedirs(args.working_directory)
	
	# Create config.yaml
	config_file = os.path.join(args.working_directory, "config.yaml")
	create_config(config_file, args)

	# Execute snakemake
	run_snakemake(config_file, args)
	
	# On quit
	print("\nThank you for using FooDMe!\n")

if __name__=='__main__':
		main()